#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os
import argparse
import subprocess as sp
import webbrowser
import signal
import sys
from util import *


VIEWER_NAME = "forensicarchitecture/mviewer"
CONT_VIEWER_NAME = VIEWER_NAME.replace("/", "_")
DIR_PATH = os.path.dirname(os.path.realpath(__file__))
ENV_FILE = "{}/.env".format(DIR_PATH)
HOME_PATH = os.path.expanduser("~")
NAME = "forensicarchitecture/mtriage"


def get_cont_name():
    """ Get name of next mtriage instance based on existing containers. """
    names = sp.check_output(["docker", "ps", "-a", "--format", "{{.Names}}"])
    if isinstance(names, bytes):
        names = []
    else:
        names = names.split("\n")
    seed = 1
    cont_name = "mtriage_{}".format(seed)
    while cont_name in names:
        seed += 1
        cont_name = "mtriage_{}".format(seed)

    return cont_name


CONT_NAME = get_cont_name()


def build(args):
    """ Collect all partial Pip and Docker files from selectors and analysers, and combine them with the core mtriage
        dependencies in src/build in order to create an appropriate Dockerfile and requirements.txt.
        NOTE: There is currently no way to include/exclude certain selector dependencies, but this build process is
              the setup for that optionality.
    """

    IS_GPU = args.gpu

    # setup
    TAG_NAME = "dev-gpu" if IS_GPU else "dev"
    DOCKER_BASE = "core-gpu" if IS_GPU else "core-cpu"

    DOCKERFILE_PARTIAL = "partial.Dockerfile"
    PIP_PARTIAL = "requirements.txt"
    BUILD_DOCKERFILE = "{}/build.Dockerfile".format(DIR_PATH)
    BUILD_PIPFILE = "{}/build.requirements.txt".format(DIR_PATH)
    CORE_PIPDEPS = "{}/src/build/core.requirements.txt".format(DIR_PATH)
    CORE_START_DOCKER = "{}/src/build/{}.start.Dockerfile".format(DIR_PATH, DOCKER_BASE)
    CORE_END_DOCKER = "{}/src/build/core.end.Dockerfile".format(DIR_PATH)
    ANALYSERS_PATH = "{}/src/lib/analysers".format(DIR_PATH)
    SELECTORS_PATH = "{}/src/lib/selectors".format(DIR_PATH)

    print("Collecting partial dependencies from selector and analyser folders...")

    with open(CORE_PIPDEPS) as cdeps:
        pipdeps = cdeps.readlines()

    with open(CORE_START_DOCKER) as dfile:
        dockerlines = dfile.readlines()

    # search all selectors/analysers for partials
    selectors = get_subdirs(SELECTORS_PATH)
    analysers = get_subdirs(ANALYSERS_PATH)

    for selector in selectors:
        docker_dep = "{}/{}/{}".format(SELECTORS_PATH, selector, DOCKERFILE_PARTIAL)
        pip_dep = "{}/{}/{}".format(SELECTORS_PATH, selector, PIP_PARTIAL)

        add_deps(docker_dep, dockerlines, should_add_dockerline)
        add_deps(pip_dep, pipdeps, should_add_pipdep)

    for analyser in analysers:
        docker_dep = "{}/{}/{}".format(ANALYSERS_PATH, analyser, DOCKERFILE_PARTIAL)
        pip_dep = "{}/{}/{}".format(ANALYSERS_PATH, analyser, PIP_PARTIAL)

        add_deps(docker_dep, dockerlines, should_add_dockerline)
        add_deps(pip_dep, pipdeps, should_add_pipdep)

    with open(CORE_END_DOCKER) as f:
        for line in f.readlines():
            dockerlines.append(line)

    # create Dockerfile and requirements.txt for build
    # if os.path.exists(BUILD_PIPFILE):
    #     os.remove(BUILD_PIPFILE)

    with open(BUILD_PIPFILE, "w") as f:
        for dep in pipdeps:
            f.write(dep)

    # if os.path.exists(BUILD_DOCKERFILE):
    #     os.remove(BUILD_DOCKERFILE)

    with open(BUILD_DOCKERFILE, "w") as f:
        for line in dockerlines:
            f.write(line)

    print("All Docker dependencies collected in build.Dockerfile.")
    print("All Pip dependencies collected in build.requirements.txt.")
    print("--------------------------------------------------------")
    if IS_GPU:
        print("GPU flag enabled, building for nvidia-docker...")
    else:
        print("Building for CPU in Docker...")

    try:
        sp.call(
            [
                "docker",
                "build",
                "-t",
                "{}:{}".format(NAME, TAG_NAME),
                "-f",
                BUILD_DOCKERFILE,
                ".",
            ]
        )
        print("Build successful, run with: \n\tpython run.py develop")
    except:
        print("Something went wrong! EEK.")

    # cleanup
    os.remove(BUILD_DOCKERFILE)
    os.remove(BUILD_PIPFILE)


def develop(args):
    TAG_NAME = "dev-gpu" if args.gpu else "dev"
    # --runtime only exists on nvidia docker, so we pass a bubblegum flag when not available
    # so that the call arguments are well formed.
    sp.call(
        [
            "docker",
            "run",
            "-it",
            "--name",
            CONT_NAME,
            "--runtime=nvidia" if args.gpu else "--ipc=host",
            "--env",
            "BASE_DIR=/mtriage",
            "--env-file={}".format(ENV_FILE),
            "--privileged",
            "-v",
            "{}:/mtriage".format(DIR_PATH),
            "-v",
            "{}/.config/gcloud:/root/.config/gcloud".format(HOME_PATH),
            "{}:{}".format(NAME, TAG_NAME),
            "/bin/bash",
        ]
    )


def clean(args):
    sp.call(["docker", "rmi", NAME])


def __run_core_tests():
    returncode = sp.call(
        [
            "docker",
            "run",
            "--env",
            "BASE_DIR=/mtriage",
            "--env-file={}".format(ENV_FILE),
            "--rm",
            "-v",
            "{}:/mtriage".format(DIR_PATH),
            "--workdir",
            "/mtriage/src",
            "{}:dev".format(NAME),
            "python",
            "-m",
            "pytest",
            ".",
        ]
    )
    if returncode is 1:
        exit(returncode)


def __run_runpy_tests():
    """ NOTE: runpy tests are not run in a docker container, as they operate on the local machine-- so this test is run
    using the LOCAL python (could be 2 or 3). """
    returncode = sp.call(["python", "-m", "pytest", "test/"])
    if returncode is 1:
        exit(returncode)


def test(args):
    print("Creating container to run tests...")
    print("----------------------------------")
    __run_core_tests()
    __run_runpy_tests()
    print("----------------------------------")
    print("All tests for mtriage done.")


def run(args):
    TAG_NAME = "dev-gpu" if args.gpu else "dev"
    # --runtime only exists on nvidia docker, so we pass a bubblegum flag when not available
    # so that the call arguments are well formed.
    sp.call(
        [
            "docker",
            "run",
            "--name",
            CONT_NAME,
            "--runtime=nvidia" if args.gpu else "--ipc=host",
            "--env",
            "BASE_DIR=/mtriage",
            "--env-file={}".format(ENV_FILE),
            "--privileged",
            "-v",
            "{}:/mtriage".format(DIR_PATH),
            "-v",
            "{}:/run_args.yaml".format(os.path.abspath(args.yaml)),
            "-v",
            "{}/.config/gcloud:/root/.config/gcloud".format(HOME_PATH),
            "{}:{}".format(NAME, TAG_NAME),
        ]
    )


if __name__ == "__main__":
    DEV_COMMANDS = {"develop": develop, "build": build, "test": test, "clean": clean}

    def yaml_type(fname):
        ext = os.path.splitext(fname)[1][1:]
        if ext not in ("yaml"):
            run_p.error("The file you specify to run mtriage must be a YAML file")
        if not os.path.exists(fname):
            run_p.error("Cannot find a file at {}.".format(fname))
        return fname

    parser = argparse.ArgumentParser(description="mtriage dev scripts")
    subparsers = parser.add_subparsers(dest="__base")

    run_p = subparsers.add_parser("run")
    run_p.add_argument("yaml", type=yaml_type)
    run_p.add_argument("--gpu", action="store_true")
    # TODO: accept an interactive option at -i

    dev_p = subparsers.add_parser("dev")
    dev_p.add_argument(
        "command",
        choices=DEV_COMMANDS.keys(),
        default="develop",
        const="develop",
        nargs="?",
    )
    dev_p.add_argument("--gpu", action="store_true")

    args = parser.parse_args()

    if args.__base == "dev":
        DEV_COMMANDS[args.command](args)
    else:
        run(args)
